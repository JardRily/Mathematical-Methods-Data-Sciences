{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JardRily/Mathematical-Methods-Data-Sciences/blob/main/MAT%20494%20Data%20Science/3.4%20Logistic%20Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zd0TrUn_iR8"
      },
      "source": [
        "# 3.4 Logistic Regression\n",
        "\n",
        "Logisitc regression is a model that uses a logistic function to model a binary independent variable. In this section we will illustrate the use of Gradient Descent on binary classification by logistic regression. Given the input data is of the form $\\{(\\alpha_i, b_i):i=1,\\ldots,n\\}$ where $\\alpha_i \\in \\mathbb{R}^d$ are the features and $b_i \\in \\{0,1\\}$ is the label. As before weuse a matrix representation: $A\\in \\mathbb{R}^{n \\times d}$ has rows $\\alpha_j^T$, $j=1, \\ldots, n$ and $b=(b_1, \\ldots, b_n)^T \\in \\{0, 1\\}^n$. We wish to find a function of the features that approximates the probability of label 1 as a linear function of features. \n",
        "\n",
        "For $x, \\alpha \\in \\mathbb{R}^d$, let $p(\\alpha ; x)$ be the probability of the output to be 1, we define $\\log \\frac{p(\\alpha ; x)}{1-p(\\alpha ; x)} = \\alpha^T x$. Here $\\alpha^T x = \\Sigma x_i \\alpha_i$ can be viewed as a regression problem which seeks the best parameters ($x$) with given data ($\\alpha$). Rearranging this expression gives $p(\\alpha ; x) = \\sigma (\\alpha^T x)$, where the sigmoid function is $\\sigma(t)=\\frac{1}{1+e^{-t}}$ for $t\\in \\mathbb{R}$. To maximize the likelihood of the data, we assume the labels are independent given the features, which is given by \n",
        "\\begin{gather*}\n",
        "\\mathscr{L}(x; A,b)=\\prod^n_{i=1} p(\\alpha_i ; x)^{b_i}(1-p(\\alpha_i ; x)^{b_i})\n",
        "\\end{gather*}\n",
        "Taking a logarithm, multiplying by $\\frac{-1}{n}$ and substituting the sigmoid function, we want to minimize the cross-entropy loss:\n",
        "\\begin{gather*}\n",
        "\\mathscr{l}(x; A,b)= - \\frac{1}{n} \\sum^n_{i=1}b_i \\log(\\sigma(\\alpha^T x))- \\frac{1}{n} \\sum^n_{i=1}(1-b_i) \\log(1-\\sigma(\\alpha^T x))\n",
        "\\end{gather*}\n",
        "That is, we solve $\\min_{x\\in \\mathbb{R}^d} \\mathscr{l}(x; A,b)$. To use gradient descent, we need to compute the gradient of $\\mathscr{l}$. We use the Chain Rule and first compute the derivative of $\\sigma$ which is $\\sigma '(t) = \\frac{e^{-t}}{(1+e^{-t})^2} = \\frac{1}{1+e^{-t}}(1-\\frac{1}{1+e^{-t}})=\\sigma (t)(1-\\sigma (t))$. \n",
        "\n",
        "It follows that $\\sigma (t)$ satisfies the logisitc differential equation. It arises in a variety of applications, including the modeling of population dynamics. here it will be a convenient way to compute the gradient. Observe that be the Chain Rule: $\\nabla_x \\sigma(\\alpha^T x) = \\sigma(\\alpha^T x)(1-\\sigma(\\alpha^T x))\\alpha$, where we use a subscript $x$ to make it clear that the gradient is with respect to $x$. \n",
        "\n",
        "With the same approach, we can plug in to get $\\nabla_x \\mathscr{l}(x; A,b) = - \\frac{1}{n} \\sum^n_{i=1} (b_i - \\sigma(\\alpha_i^T x)) \\alpha_i $. To compute the Hessian we have $\\nabla^2_x \\mathscr{l}(x; A,b) = - \\frac{1}{n} \\sum^n_{i=1}\\sigma(\\alpha_i^T x)(1-\\sigma(\\alpha_i^T x))\\alpha_i \\alpha_i^T$ where $\\nabla^2_x$ indicates the Hessian with respect to $x$. Now each $\\alpha_i \\alpha_i^T$ is a symmetric matrix and PSD. As a result, the function $\\mathscr{l}(x; A,b)$ is convex as a function of $x\\in \\mathbb{R}^d$. We want to comment that convexity is one reason for working with the cross-entropy loss rather than the mean squared error.\n",
        "\n",
        "To update iteration formula: for step size $\\beta$, one step of gradient descent is therefore $x^{k+1}=x^k + \\beta \\frac{1}{n}\\sum^n_{i=1}(b_i-\\sigma(\\alpha^T_i x^k))\\alpha_i$. In stochastic gradient descent, a variant of gradient descent, we pick a sample $I$ uniformly at random in ${1, \\ldots, n}$ and update as follows $x^{k+1}=x^k + \\beta (b_I-\\sigma(\\alpha^T_I x^k))\\alpha_I$."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "a95447f1ef4a7eeb81744d913c0526f7f23f9aec6d814ce91d70cd9b0479878c"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}